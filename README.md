# ğŸ™ï¸ EmotionAI Voice

> An AI-powered application for detecting human emotions through voice input, designed for healthcare and human-computer interaction enhancement.

---

## ğŸ“Œ Overview

**EmotionAI Voice** is an open-source deep learning project that classifies vocal emotions using raw `.wav` audio.  
It's designed for applications in mental health monitoring, UX analysis, and intelligent speech interfaces.

ğŸ”¬ The model is trained **from scratch**, using spectrogram-based audio features, and aims to recognize 8 core emotions.

---

## ğŸ¯ Features

- ğŸ§  Emotion recognition: `neutral`, `calm`, `happy`, `sad`, `angry`, `fearful`, `disgust`, `surprised`
- ğŸ§ Accepts `.wav` audio inputs (from RAVDESS dataset)
- ğŸ“Š CNN and CNN+GRU models implemented in PyTorch
- ğŸ” Real-time evaluation with confusion matrix and accuracy tracking
- ğŸ› ï¸ Fully open-source and customizable (no pre-trained models)
- ğŸ§ª Includes **SpecAugment** for data augmentation (frequency/time masking)

---

## ğŸ“š Dataset â€” RAVDESS

We use the [**RAVDESS** dataset](https://zenodo.org/record/1188976), which includes:

- ğŸ­ 24 professional actors (balanced male/female)
- ğŸ™ï¸ 1440 `.wav` files (16-bit, 48kHz)
- 8 labeled emotions:  
  `neutral`, `calm`, `happy`, `sad`, `angry`, `fearful`, `disgust`, `surprised`

Each `.wav` file is preprocessed into a **Mel spectrogram** and stored as `.npy` format.

---

## ğŸ§  Model Architectures

### 2 different models
#### âœ… CNN (Best Performance)
- 3x Conv1D + ReLU + MaxPool
- Fully connected layers
- Dropout regularization (adjustable)

#### ğŸ” CNN + GRU
- CNN front-end for spatial encoding
- GRU (recurrent layers) to capture temporal dynamics
- Lower accuracy than CNN-only model

---

### ğŸ§ª SpecAugment: Data Augmentation

To improve generalization, we implemented `SpecAugmentTransform` which applies:

- ğŸ•’ **Time masking**: hides random time intervals
- ğŸ“¡ **Frequency masking**: hides random mel frequency bands

---

### ğŸ“ˆ Training Results

- Best Validation Accuracy: **~49.6%**
- Training set: Actors 1â€“20
- Validation set: Actors 21â€“24

---

**Confusion Matrix Example:**

![Confusion Matrix](./confusion_matrix.png)

## ğŸš€ Getting Started

### 1. Install dependencies

```bash
pip install -r requirements.txt

### 2. Download dataset from Kaggle

Follow the instructions in the README.md located in the data folder

### 3 . Train the model

```bash
python src/train.py

### 4.  Evaluation the performances with a confusion matrix

```bash
python src/confusion_matrix.py


